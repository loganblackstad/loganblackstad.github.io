{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "author:  Logan Blackstad\n",
    "file:    atlanta-weather-plotting.py\n",
    "date:    Dec 06 2018\n",
    "\n",
    "Description:\n",
    "Goal --> Plot the daily min and max temps for ATL in 2016 vs 2017 vs 2018\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import statsmodels\n",
    "import ggplot\n",
    "import seaborn as sb\n",
    "import altair\n",
    "import plotnine as pn\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST, get weather data:\n",
    "\n",
    "I queried weather data from NOAA because it was free:\n",
    "https://www.ncdc.noaa.gov/\n",
    "\n",
    "Parameters: \n",
    "city  = Atlanta\n",
    "dates = 01/01/2016 to 12/01/2018\n",
    "\n",
    "NOAA sends an email file containing the csv of weather data to the email youy specify.\n",
    "\n",
    "I then imported atlanta-weather.csv as a pandas DataFrame. (Important: the .csv file has to be in the same directory as your jupyter file.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_w = pd.read_csv(\"test.csv\")\n",
    "test_w.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl_w = pd.read_csv(\"atlanta-weather.csv\", dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atl_w_col_names = list(atl_w.columns.values)\n",
    "print (atl_w_col_names, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(atl_w.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_dict = {}\n",
    "for col in atl_w:\n",
    "    uniq_dict[col] = atl_w[col].value_counts().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_dict\n",
    "\n",
    "for key in uniq_dict: \n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = datetime.datetime(2018, 12, 1) - datetime.datetime(2016, 1, 1)\n",
    "print(\"There are {} days between Jan 01 2016 and Dec 01 2018 [inclusive]\".format(days.days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_per_station = atl_w.groupby('NAME')['DATE'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_per_station.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = atl_w[['NAME', 'DATE', 'TAVG', 'TMAX', 'TMIN']].copy()\n",
    "df_airport = df_temp.loc[df_temp['NAME'] == \"ATLANTA HARTSFIELD INTERNATIONAL AIRPORT, GA US\"]\n",
    "df_airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = df_airport\n",
    "dfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = dfa.astype({\"TAVG\": float, \"TMAX\": float, \"TMIN\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pp.subplots(figsize=(13,6))\n",
    "\n",
    "mask2016 = dfa[(dfa['DATE']>='2016-1-1') & (dfa['DATE']<'2017-1-1')] \n",
    "mask2017 = dfa[(dfa['DATE']>='2017-1-1') & (dfa['DATE']<'2018-1-1')] \n",
    "mask2018 = dfa[(dfa['DATE']>='2018-1-1') & (dfa['DATE']<='2018-12-1')] \n",
    "\n",
    "mask2016.plot(kind='line',x='DATE',y='TMAX', ax=ax, color='red')\n",
    "mask2016.plot(kind='line',x='DATE',y='TMIN', ax=ax, color='blue')\n",
    "\n",
    "\n",
    "pp.ylabel('Temperature (Â°F)')\n",
    "pp.title('\\nATL Airport Temperature (min, avg, max)\\n[Jan 01 2016 to Dec 01 2018]\\n', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days = list(range(1,len(dfa)+1))\n",
    "\n",
    "list_x = all_days\n",
    "list_y = dfa['TMAX']\n",
    "\n",
    "\n",
    "def plot_smoothed(drange, temp, win=10):\n",
    "    smoothed = np.correlate(temp, np.ones(win)/win,'same')    \n",
    "    pp.plot(drange,smoothed)\n",
    "\n",
    "#pp.plot(list_x,list_y)\n",
    "#plot_smoothed()\n",
    "\n",
    "fig, ax = pp.subplots(figsize=(13,6))\n",
    "plot_smoothed(all_days, dfa['TMAX'], 20)\n",
    "plot_smoothed(all_days, dfa['TMIN'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
